import torch 
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from tqdm import tqdm
from torchvision import datasets, transforms
from torchvision.models import efficientnet_b0
from torchvision.models import EfficientNet_B0_Weights
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import os
from PIL import Image

# For skipping over corrupted img or jpg files in the database
def pil_loader(path):
    """Loads an image and skips if corrupted."""
    try:
        with open(path, "rb") as f:
            img = Image.open(f)
            return img.convert("RGB")
    except Exception as e:
        print(f"Warning: Could not load image {path} ({e})")
        return None

class SafeImageFolder(datasets.ImageFolder):
    def __getitem__(self, index):
        while True:
            path, target = self.samples[index]
            sample = self.loader(path)
            if sample is not None:
                if self.transform is not None:
                    sample = self.transform(sample)
                if self.target_transform is not None:
                    target = self.target_transform(target)
                return sample, target
            else:
                index = (index + 1) % len(self.samples)

dataset_path = "data/Tomato_Plant_Stages_Dataset"

transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

dataset = SafeImageFolder(root=dataset_path, transform=transform_train, loader=pil_loader)

name_classes = dataset.classes
print(f"Found classes: {name_classes}")
print(f"Total images: {len(dataset)}")

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

val_dataset.dataset.transform = transform_val

load_train = DataLoader(train_dataset, batch_size = 16, shuffle=True)
load_val = DataLoader(val_dataset, batch_size = 16)

print(f"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}")

# Loading EfficientNet- B0 pretrained model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1) # it was parameter pretrained before I put weights

# To prevent overfitting - transfer learning: keep learned features from ImageNet, retrain just the classifier to match your tomato stages
for param in model.features.parameters():
    param.requires_grad = False

num_classes = len(name_classes)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss() # Loss func
optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

num_epochs = 20
best_val_acc = 0.0
train_losses, val_losses = [], []
train_accs, val_accs = [], []

print("Starting training...")

for epoch in range(num_epochs):
    print(f"\nEpoch {epoch + 1}/{num_epochs}")
    print("-" * 30)

    train_loss, train_correct = 0.0, 0
    val_loss, val_correct = 0.0, 0


    model.train()
    for inputs, labels in tqdm(load_train, desc="Training", leave=False):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        
        outputs = model(inputs) # Forward pass
        loss = criterion(outputs, labels) # loss compuitation
        loss.backward() # Backprop
        optimizer.step() # weight update

        train_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        train_correct += torch.sum(preds == labels.data)

    # Validation phase
    model.eval()
    with torch.no_grad():
        for inputs, labels in tqdm(load_val, desc="Validating", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            val_correct += torch.sum(preds == labels.data)

    train_loss = train_loss / len(load_train.dataset)
    val_loss = val_loss / len(load_val.dataset)
    train_acc = train_correct.double() / len(load_train.dataset)
    val_acc = val_correct.double() / len(load_val.dataset)
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc.item())
    val_accs.append(val_acc.item())

    # Save best model
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_acc': val_acc,
            'class_names': name_classes,
            'num_classes': num_classes
        }, "best_model_results.pth")
        print(f"Best model results saved! Val Accuracy: {val_acc:.4f}")
    
    scheduler.step()

    print(f"Train loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}")
    print(f"Val loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")

print(f"\nTraining completed! Best validation accuracy: {best_val_acc:.4f}")

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accs, label='Train Accuracy')
plt.plot(val_accs, label='Val Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.savefig('training_curves.png')
plt.show()

